{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MindSpore构造平方损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入所需库和函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import context\n",
    "import numpy as np\n",
    "from mindspore import dataset as ds\n",
    "from mindspore import nn, Tensor, Model\n",
    "import time\n",
    "from mindspore.train.callback import Callback, LossMonitor\n",
    "import mindspore as ms\n",
    "import mindspore.ops as ops\n",
    "from mindspore.nn import L1Loss\n",
    "ms.common.set_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(num, a=2.0, b=3.0, c=5.0):\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-1.0, 1.0)\n",
    "        y = np.random.uniform(-1.0, 1.0)\n",
    "        noise = np.random.normal(0, 0.03)\n",
    "        z = a * x ** 2 + b * y ** 3 + c + noise\n",
    "        yield np.array([[x**2], [y**3]],dtype=np.float32).reshape(1,2), np.array([z]).astype(np.float32)\n",
    " \n",
    "def create_dataset(num_data, batch_size=16, repeat_size=1):\n",
    "    input_data = ds.GeneratorDataset(list(get_data(num_data)), column_names=['xy','z'])\n",
    "    input_data = input_data.batch(batch_size)\n",
    "    input_data = input_data.repeat(repeat_size)\n",
    "    return input_data\n",
    " \n",
    "data_number = 160\n",
    "batch_number = 10\n",
    "repeat_number = 10\n",
    " \n",
    "ds_train = create_dataset(data_number, batch_size=batch_number, repeat_size=repeat_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义一个简单的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc = nn.Dense(2, 1, 0.02, 0.02)\n",
    " \n",
    "    def construct(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型中参数维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape is: 2\n",
      "Parameter (name=fc.weight, shape=(1, 2), dtype=Float32, requires_grad=True) [[0.02 0.02]]\n",
      "Parameter (name=fc.bias, shape=(1,), dtype=Float32, requires_grad=True) [0.02]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "net = LinearNet()\n",
    "model_params = net.trainable_params()\n",
    "print ('Param Shape is: {}'.format(len(model_params)))\n",
    "for net_param in net.trainable_params():\n",
    "    print(net_param, net_param.asnumpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重写损失函数，自定义平方损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class quadratic_loss(L1Loss):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(quadratic_loss, self).__init__(reduction)\n",
    "        self.square = ops.Square()\n",
    " \n",
    "    def construct(self, base, target):\n",
    "        x = 0.5 * self.square(base - target)\n",
    "        return self.get_loss(x)\n",
    " \n",
    "user_loss = quadratic_loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 160, loss is 1.2997653484344482\n",
      "Parameter (name=fc.weight, shape=(1, 2), dtype=Float32, requires_grad=True) [[1.3762274  0.01708973]]\n",
      "Parameter (name=fc.bias, shape=(1,), dtype=Float32, requires_grad=True) [5.0189986]\n",
      "The total time cost is: 20.236934423446655s\n"
     ]
    }
   ],
   "source": [
    "optim = nn.Momentum(net.trainable_params(), learning_rate=0.01, momentum=0.6)\n",
    "model = Model(net, user_loss, optim)\n",
    " \n",
    "epoch = 1\n",
    "model.train(epoch, ds_train, callbacks=[LossMonitor(10)], dataset_sink_mode=True)\n",
    " \n",
    "for net_param in net.trainable_params():\n",
    "    print(net_param, net_param.asnumpy())\n",
    " \n",
    "print ('The total time cost is: {}s'.format(time.time() - start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "26fcd935751ef84cad2d7f9e4bd00a41b458c58fd62c8d14685a9368156264ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
